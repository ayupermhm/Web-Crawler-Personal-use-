# About The Project
There are 2 types of crawlers in this file: Specific Website crawlers and Automated Web Crawlers for generating data from multiple sites. 
Specific Website Crawlers crawls specific websites that have been used before. These crawlers have a high accuracy rate and are guaranteed to produce.
Automated Web Crawlers for generating data from multiple sites allows users to continuously add URLs to link_bank.csv. Since this method is utilising Machine Learning, this method is high experimental and cannot guarantee perfect results. 

## Built With
- Python 

## Getting Started 
The following sections will introduce you to the multiple crawlers and the important instructions you would need to follow in order to run the files. 

## Specific Site Crawlers
### 1. Companies within Food Navigator - Food Navigator (and the 4 regions), Nutraingredients (and the 4 regions), Confectionary News, Dairy Reporter, etc
Before starting, install the following packages using your command prompt:
- Request
```bash
pip install requests_html
```
- Pandas
```bash 
pip install Pandas
```
### 2. FoodDive, Foodbev

### 3. Packworld

## Automated Web Crawlers 

## Contact
Ayp - aayphxm@gmail.com
Project Link - 

## Acknowledgements